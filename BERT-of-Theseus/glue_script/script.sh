#!/bin/bash
# rte
# nohup bash glue_script/script.sh &
# nohup bash -c 'CUDA_VISIBLE_DEVICES=0 python run_glue_MPO_losslayer.py --model_name_or_path /mnt/zhanyuliang/data/nlp_data/theseus/BertFineTrain/download/rte/bert-base-uncased-RTE/ --task_name rte --do_train --do_eval --do_lower_case --data_dir /mnt/zhanyuliang/data/nlp_data/GLUE/RTE --max_seq_length 128 --per_gpu_train_batch_size 32 --per_gpu_eval_batch_size 32 --learning_rate 1e-6 --save_steps 50 --num_train_epochs 20 --output_dir /mnt/zhanyuliang/data/checkpoint/nlp/theseus/save_successor/ --evaluate_during_training --replacing_rate 0.3 --scheduler_type linear --scheduler_linear_k 0.0001 --overwrite_output_dir' >log/rte_mpo.log >&1 &
# wait
# # mrpc
# nohup bash -c 'CUDA_VISIBLE_DEVICES=0 python run_glue_MPO_losslayer.py --model_name_or_path /mnt/zhanyuliang/data/nlp_data/theseus/BertFineTrain/download/mrpc/bert-base-uncased-glue-mrpc/ --task_name mrpc --do_train --do_eval --do_lower_case --data_dir /mnt/zhanyuliang/data/nlp_data/GLUE/MRPC --max_seq_length 128 --per_gpu_train_batch_size 32 --per_gpu_eval_batch_size 32 --learning_rate 1e-6 --save_steps 50 --num_train_epochs 20 --output_dir /mnt/zhanyuliang/data/checkpoint/nlp/theseus/save_successor/ --evaluate_during_training --replacing_rate 0.3 --scheduler_type linear --scheduler_linear_k 0.0001 --overwrite_output_dir' >log/mrpc_mpo.log >&1 &
# wait
# nohup bash -c 'CUDA_VISIBLE_DEVICES=0 python run_glue_MPO_losslayer.py --model_name_or_path /mnt/zhanyuliang/data/nlp_data/theseus/BertFineTrain/download/mrpc/bert-base-uncased-glue-mrpc/ --task_name mrpc --do_train --do_eval --do_lower_case --data_dir /mnt/zhanyuliang/data/nlp_data/GLUE/MRPC --max_seq_length 128 --per_gpu_train_batch_size 32 --per_gpu_eval_batch_size 32 --learning_rate 1e-6 --save_steps 50 --num_train_epochs 20 --output_dir /mnt/zhanyuliang/data/checkpoint/nlp/theseus/save_successor/ --evaluate_during_training --replacing_rate 0.3 --scheduler_type linear --scheduler_linear_k 0.0006 --overwrite_output_dir' >log/mrpc_mpo_2.log >&1 &
# wait
# # sts-b
# nohup bash -c 'CUDA_VISIBLE_DEVICES=0 python run_glue_MPO_losslayer.py --model_name_or_path /mnt/zhanyuliang/data/nlp_data/theseus/BertFineTrain/download/stsb/bert-base-uncased-stsb/ --task_name sts-b --do_train --do_eval --do_lower_case --data_dir /mnt/zhanyuliang/data/nlp_data/GLUE/STS-B --max_seq_length 128 --per_gpu_train_batch_size 32 --per_gpu_eval_batch_size 32 --learning_rate 2e-5 --save_steps 50 --num_train_epochs 15 --output_dir /mnt/zhanyuliang/data/checkpoint/nlp/theseus/save_successor/ --evaluate_during_training --replacing_rate 0.3 --scheduler_type linear --scheduler_linear_k 0.0001 --overwrite_output_dir' >log/stsb_mpo.log >&1 &
# wait
# nohup bash -c 'CUDA_VISIBLE_DEVICES=0 python run_glue_MPO_losslayer.py --model_name_or_path /mnt/zhanyuliang/data/nlp_data/theseus/BertFineTrain/download/stsb/bert-base-uncased-stsb/ --task_name sts-b --do_train --do_eval --do_lower_case --data_dir /mnt/zhanyuliang/data/nlp_data/GLUE/STS-B --max_seq_length 128 --per_gpu_train_batch_size 32 --per_gpu_eval_batch_size 32 --learning_rate 2e-5 --save_steps 50 --num_train_epochs 15 --output_dir /mnt/zhanyuliang/data/checkpoint/nlp/theseus/save_successor/ --evaluate_during_training --replacing_rate 0.3 --scheduler_type linear --scheduler_linear_k 0.0006 --overwrite_output_dir' >log/stsb_mpo_2.log >&1 &
# wait
# # cola
# nohup bash -c 'CUDA_VISIBLE_DEVICES=0 python run_glue_MPO_losslayer.py --model_name_or_path /mnt/zhanyuliang/data/nlp_data/theseus/BertFineTrain/download/cola/bert-base-uncased-finetuned-cola/ --task_name cola --do_train --do_eval --do_lower_case --data_dir /mnt/zhanyuliang/data/nlp_data/GLUE/CoLA --max_seq_length 128 --per_gpu_train_batch_size 32 --per_gpu_eval_batch_size 32 --learning_rate 1e-4 --save_steps 50 --num_train_epochs 20 --output_dir /mnt/zhanyuliang/data/checkpoint/nlp/theseus/save_successor/ --evaluate_during_training --replacing_rate 0.3 --scheduler_type linear --scheduler_linear_k 0.0001 --overwrite_output_dir' >log/cola_mpo.log >&1 &
# wait
# nohup bash -c 'CUDA_VISIBLE_DEVICES=0 python run_glue_MPO_losslayer.py --model_name_or_path /mnt/zhanyuliang/data/nlp_data/theseus/BertFineTrain/download/cola/bert-base-uncased-finetuned-cola/ --task_name cola --do_train --do_eval --do_lower_case --data_dir /mnt/zhanyuliang/data/nlp_data/GLUE/CoLA --max_seq_length 128 --per_gpu_train_batch_size 32 --per_gpu_eval_batch_size 32 --learning_rate 1e-4 --save_steps 50 --num_train_epochs 20 --output_dir /mnt/zhanyuliang/data/checkpoint/nlp/theseus/save_successor/ --evaluate_during_training --replacing_rate 0.3 --scheduler_type linear --scheduler_linear_k 0.0006 --overwrite_output_dir' >log/cola_mpo_2.log >&1 &
# wait
# sst2
nohup bash -c 'CUDA_VISIBLE_DEVICES=0 python run_glue_MPO_losslayer.py --model_name_or_path /mnt/zhanyuliang/data/nlp_data/theseus/BertFineTrain/download/sst2/bert-base-uncased-finetuned-sst2/ --task_name sst-2 --do_train --do_eval --do_lower_case --data_dir /mnt/zhanyuliang/data/nlp_data/GLUE/SST-2 --max_seq_length 128 --per_gpu_train_batch_size 32 --per_gpu_eval_batch_size 32 --learning_rate 1e-6 --save_steps 50 --num_train_epochs 20 --output_dir /mnt/zhanyuliang/data/checkpoint/nlp/theseus/save_successor/ --evaluate_during_training --replacing_rate 0.3 --scheduler_type linear --scheduler_linear_k 0.0003 --overwrite_output_dir' >log/sst2_mpo.log >&1 &
wait
nohup bash -c 'CUDA_VISIBLE_DEVICES=2 python run_glue_MPO_losslayer.py --model_name_or_path /mnt/zhanyuliang/data/nlp_data/theseus/BertFineTrain/download/sst2/bert-base-uncased-finetuned-sst2/ --task_name sst-2 --do_train --do_eval --do_lower_case --data_dir /mnt/zhanyuliang/data/nlp_data/GLUE/SST-2 --max_seq_length 128 --per_gpu_train_batch_size 32 --per_gpu_eval_batch_size 32 --learning_rate 3e-6 --save_steps 50 --num_train_epochs 20 --output_dir /mnt/zhanyuliang/data/checkpoint/nlp/theseus/save_successor/ --evaluate_during_training --replacing_rate 0.3 --scheduler_type linear --scheduler_linear_k 0.0003 --overwrite_output_dir' >log/sst2_mpo_2.log >&1 &
wait
nohup bash -c 'CUDA_VISIBLE_DEVICES=3 python run_glue_MPO_losslayer.py --model_name_or_path /mnt/zhanyuliang/data/nlp_data/theseus/BertFineTrain/download/sst2/bert-base-uncased-finetuned-sst2/ --task_name sst-2 --do_train --do_eval --do_lower_case --data_dir /mnt/zhanyuliang/data/nlp_data/GLUE/SST-2 --max_seq_length 128 --per_gpu_train_batch_size 32 --per_gpu_eval_batch_size 32 --learning_rate 6e-6 --save_steps 50 --num_train_epochs 20 --output_dir /mnt/zhanyuliang/data/checkpoint/nlp/theseus/save_successor/ --evaluate_during_training --replacing_rate 0.3 --scheduler_type linear --scheduler_linear_k 0.0003 --overwrite_output_dir' >log/sst2_mpo_3.log >&1 &
wait



